{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd084eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include necessary libraries \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Example text\n",
    "text = \"Tokenization is an important step in natural language processing.\"\n",
    "\n",
    "# Word Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Print the tokens\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include necessary libraries \n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#Example sentence\n",
    "sentence = \"I am Aman.I am 19 years old.I like playing cricket.\"\n",
    "\n",
    "# Sentence Tokeniztion\n",
    "sentences = sent_tokenize(sentence)\n",
    "\n",
    "# Print the Sentences\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include necessary libraries\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#create an object ( Stemming for words )\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# List of words\n",
    "words = ['eat','ate','eating','eatable','ability','woking','worked']\n",
    "\n",
    "# Printing stemmed words\n",
    "for word in words :\n",
    "    root_word = stemmer.stem(word)\n",
    "    print(root_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f22c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include necessary libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#create an object ( Stemming for sentences )\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# List of words\n",
    "sentence = \"studies studying crying cries\"\n",
    "\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "# Printing stemmed words\n",
    "for word in words :\n",
    "    root_word = stemmer.stem(word)\n",
    "    print(f\"Stemming for {word} is {root_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8401303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include necessary libraries\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#create an object ( Lemmatization for sentences )\n",
    "lemmatizer =  WordNetLemmatizer()\n",
    "\n",
    "# List of words\n",
    "words = ['eat','ate','eating','eatable','ability','woking','worked']\n",
    "\n",
    "# Printing lemmatizedwords\n",
    "for word in words :\n",
    "    root_word = lemmatizer.lemmatize(word)\n",
    "    print(f\"Lemmatization for {word} is {root_word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include necessary libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#create an object ( Lemmatization for sentences )\n",
    "lemmatizer =  WordNetLemmatizer()\n",
    "\n",
    "# List of words\n",
    "sentence = \"studies studying crying cries\"\n",
    "\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "# Printing lemmatizedwords\n",
    "for word in words :\n",
    "    root_word = lemmatizer.lemmatize(word)\n",
    "    print(f\"Lemmatization for {word} is {root_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include necessary libraries\n",
    "from nltk import pos_tag\n",
    "\n",
    "# First tokenize the words \n",
    "wt2 = ['eat','ate','write','wrong','good','bad','moving','heartfelt']\n",
    "\n",
    "# Perform POS tagging for Sentences\n",
    "pos_tags = pos_tag(wt2)\n",
    "\n",
    "# Print POS tags\n",
    "print(\"\\nPOS Tags:\")\n",
    "for word, tag in pos_tags:\n",
    "    print(word, \"-\", tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b75cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include necessary libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# First tokenize the words \n",
    "v1 = \"Hello there i am aman nice to meet you\"\n",
    "wt1 = word_tokenize(v1)\n",
    "\n",
    "\n",
    "# Perform POS tagging for Sentences\n",
    "pos_tags = pos_tag(wt1)\n",
    "\n",
    "# Print POS tags\n",
    "print(\"\\nPOS Tags:\")\n",
    "for word, tag in pos_tags:\n",
    "    print(word, \"-\", tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.help.brown_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4921e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
