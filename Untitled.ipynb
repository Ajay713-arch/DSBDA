{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a92a88c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement math (from versions: none)\n",
      "ERROR: No matching distribution found for math\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0.post5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.24.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (2.0.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install math\n",
    "!pip install sklearn\n",
    "!pip install numpy\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88037cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a667b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sentence = \"Data Science is the sexiest job of the 21st century\"\n",
    "second_sentence = \"machine learning is the key for data science\"\n",
    "\n",
    "#split so each word have their own string\n",
    "\n",
    "first_sentence = first_sentence.split(\" \")\n",
    "second_sentence = second_sentence.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb515123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job', 'for', 'science', 'Science', 'key', 'of', 'is', 'the', 'machine', 'Data', 'century', 'data', 'learning', 'sexiest', '21st'}\n"
     ]
    }
   ],
   "source": [
    "#join them to remove common duplicate words\n",
    "total= set(first_sentence).union(set(second_sentence))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a3c7a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDictA = dict.fromkeys(total, 0) \n",
    "wordDictB = dict.fromkeys(total, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14b08ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in first_sentence:\n",
    "    wordDictA[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "56b52c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in second_sentence:\n",
    "    wordDictB[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89d8e755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>for</th>\n",
       "      <th>science</th>\n",
       "      <th>Science</th>\n",
       "      <th>key</th>\n",
       "      <th>of</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>machine</th>\n",
       "      <th>Data</th>\n",
       "      <th>century</th>\n",
       "      <th>data</th>\n",
       "      <th>learning</th>\n",
       "      <th>sexiest</th>\n",
       "      <th>21st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job  for  science  Science  key  of  is  the  machine  Data  century  data  \\\n",
       "0    1    0        0        1    0   1   1    2        0     1        1     0   \n",
       "1    0    1        1        0    1   0   1    1        1     0        0     1   \n",
       "\n",
       "   learning  sexiest  21st  \n",
       "0         0        1     1  \n",
       "1         1        0     0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26a4c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, doc):\n",
    "    tfDict = {}\n",
    "    corpusCount = len(doc)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(corpusCount)\n",
    "    return(tfDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "906b2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running our sentences through the tf function:\n",
    "\n",
    "tfFirst = computeTF(wordDictA, first_sentence)\n",
    "tfSecond = computeTF(wordDictB, second_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "054ac4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to dataframe for visualization\n",
    "tf = pd.DataFrame([tfFirst, tfSecond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93fc84e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   job    for  science  Science    key   of     is    the  machine  Data  \\\n",
      "0  0.1  0.000    0.000      0.1  0.000  0.1  0.100  0.200    0.000   0.1   \n",
      "1  0.0  0.125    0.125      0.0  0.125  0.0  0.125  0.125    0.125   0.0   \n",
      "\n",
      "   century   data  learning  sexiest  21st  \n",
      "0      0.1  0.000     0.000      0.1   0.1  \n",
      "1      0.0  0.125     0.125      0.0   0.0  \n"
     ]
    }
   ],
   "source": [
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c53a6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
    "        \n",
    "    return(idfDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4cb5e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputing our sentences in the log file\n",
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f48e9ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8c2a14ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running our two sentences through the IDF:\n",
    "idfFirst = computeTFIDF(tfFirst, idfs)\n",
    "idfSecond = computeTFIDF(tfSecond, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6bc9bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        job       for   science   Science       key        of        is  \\\n",
      "0  0.030103  0.000000  0.000000  0.030103  0.000000  0.030103  0.030103   \n",
      "1  0.000000  0.037629  0.037629  0.000000  0.037629  0.000000  0.037629   \n",
      "\n",
      "        the   machine      Data   century      data  learning   sexiest  \\\n",
      "0  0.060206  0.000000  0.030103  0.030103  0.000000  0.000000  0.030103   \n",
      "1  0.037629  0.037629  0.000000  0.000000  0.037629  0.037629  0.000000   \n",
      "\n",
      "       21st  \n",
      "0  0.030103  \n",
      "1  0.000000  \n"
     ]
    }
   ],
   "source": [
    "#putting it in a dataframe\n",
    "idf= pd.DataFrame([idfFirst, idfSecond])\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08fe023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\234869\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.24.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9af30a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first step is to import the library\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "98fff8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the sentence, make sure all words are lowercase or you will run #into error. for simplicity, I just made the same sentence all #lowercase\n",
    "firstV= \"Data Science is the sexiest job of the 21st century\"\n",
    "secondV= \"machine learning is the key for data science\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa4f3bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the TfidfVectorizer\n",
    "vectorize= TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8dcdfbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the model and passing our sentences right away:\n",
    "response= vectorize.fit_transform([firstV, secondV])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "520b9bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.34211869506421816\n",
      "  (0, 0)\t0.34211869506421816\n",
      "  (0, 9)\t0.34211869506421816\n",
      "  (0, 5)\t0.34211869506421816\n",
      "  (0, 11)\t0.34211869506421816\n",
      "  (0, 12)\t0.48684053853849035\n",
      "  (0, 4)\t0.24342026926924518\n",
      "  (0, 10)\t0.24342026926924518\n",
      "  (0, 2)\t0.24342026926924518\n",
      "  (1, 3)\t0.40740123733358447\n",
      "  (1, 6)\t0.40740123733358447\n",
      "  (1, 7)\t0.40740123733358447\n",
      "  (1, 8)\t0.40740123733358447\n",
      "  (1, 12)\t0.28986933576883284\n",
      "  (1, 4)\t0.28986933576883284\n",
      "  (1, 10)\t0.28986933576883284\n",
      "  (1, 2)\t0.28986933576883284\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab4d446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
